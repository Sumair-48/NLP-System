# Project Structure:
# todo-nlp-service/
# ‚îú‚îÄ‚îÄ main.py              # FastAPI application
# ‚îú‚îÄ‚îÄ nlp_utils.py         # NLP processing utilities
# ‚îú‚îÄ‚îÄ app.py               # Streamlit UI
# ‚îî‚îÄ‚îÄ requirements.txt     # Python dependencies

# =============================================================================
# main.py - FastAPI Application
# =============================================================================

from fastapi import FastAPI, HTTPException
from fastapi.responses import JSONResponse
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import Optional
import logging
from nlp_utils import process_text_input

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Initialize FastAPI app
app = FastAPI(
    title="To-Do NLP Automation API",
    description="NLP-powered task automation endpoint for processing text inputs",
    version="1.0.0"
)

# Add CORS middleware for React frontend integration
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # Configure appropriately for production
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Pydantic models for request/response
class TextInput(BaseModel):
    text: str

class TaskResponse(BaseModel):
    intent: str
    task_name: Optional[str] = None
    task_time: Optional[str] = None
    raw_text: str

@app.get("/")
async def root():
    """Health check endpoint"""
    return {"message": "To-Do NLP Automation API is running", "status": "healthy"}

@app.post("/process-text", response_model=TaskResponse)
async def process_text(input_data: TextInput):
    """
    Process text input for task-related intent recognition and entity extraction
    """
    try:
        logger.info(f"Processing text input: {input_data.text}")
        result = process_text_input(input_data.text)
        logger.info(f"Text processing result: {result}")
        return result
    except Exception as e:
        logger.error(f"Error processing text input: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Error processing text: {str(e)}")

@app.get("/health")
async def health_check():
    """Extended health check with service status"""
    return {
        "status": "healthy",
        "service": "To-Do NLP Automation API",
        "endpoints": {
            "/process-text": "Process text input for task automation"
        }
    }

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000, reload=True)

# =============================================================================
# nlp_utils.py - NLP Processing Utilities
# =============================================================================

import requests
import json
import logging
from datetime import datetime
from typing import Dict, Any, Optional
import vosk
import wave
import subprocess
import tempfile
import os

# OpenRouter API Configuration
API_KEY = "sk-or-v1-your-openrouter-api-key-here"  # Replace with your actual API key
OPENROUTER_URL = "https://openrouter.ai/api/v1/chat/completions"
MODEL_NAME = "mistralai/mistral-small-3.2-24b-instruct:free"

# Configure logging
logger = logging.getLogger(__name__)

# Initialize Vosk model (download model first)
# Download from: https://alphacephei.com/vosk/models
VOSK_MODEL_PATH = "./vosk-models/vosk-model-en-us-0.22"  # Update path as needed

try:
    if os.path.exists(VOSK_MODEL_PATH):
        vosk_model = vosk.Model(VOSK_MODEL_PATH)
        logger.info("Vosk model loaded successfully")
    else:
        vosk_model = None
        logger.warning(f"Vosk model not found at {VOSK_MODEL_PATH}. Voice processing will be disabled.")
except Exception as e:
    vosk_model = None
    logger.error(f"Failed to load Vosk model: {str(e)}")

def convert_audio_to_wav(input_path: str) -> str:
    """Convert audio file to WAV format using ffmpeg"""
    output_path = input_path.replace(os.path.splitext(input_path)[1], "_converted.wav")
    
    try:
        # Use ffmpeg to convert to WAV format suitable for Vosk
        subprocess.run([
            'ffmpeg', '-i', input_path, 
            '-acodec', 'pcm_s16le', 
            '-ac', '1', 
            '-ar', '16000', 
            output_path, '-y'
        ], check=True, capture_output=True)
        return output_path
    except subprocess.CalledProcessError as e:
        logger.error(f"FFmpeg conversion failed: {e}")
        # If ffmpeg fails, try to use the original file
        return input_path
    except FileNotFoundError:
        logger.warning("FFmpeg not found. Using original audio file.")
        return input_path

def voice_to_text(audio_path: str) -> str:
    """Convert voice audio to text using Vosk (offline)"""
    if vosk_model is None:
        raise Exception("Vosk model not available. Please download and configure the model.")
    
    try:
        # Convert audio if necessary
        wav_path = convert_audio_to_wav(audio_path)
        
        # Open audio file
        wf = wave.open(wav_path, "rb")
        
        # Check audio format
        if wf.getnchannels() != 1 or wf.getsampwidth() != 2 or wf.getframerate() != 16000:
            logger.warning("Audio format may not be optimal for Vosk")
        
        # Initialize recognizer
        rec = vosk.KaldiRecognizer(vosk_model, wf.getframerate())
        
        # Process audio
        transcript_parts = []
        while True:
            data = wf.readframes(4000)
            if len(data) == 0:
                break
            if rec.AcceptWaveform(data):
                result = json.loads(rec.Result())
                if result.get('text'):
                    transcript_parts.append(result['text'])
        
        # Get final result
        final_result = json.loads(rec.FinalResult())
        if final_result.get('text'):
            transcript_parts.append(final_result['text'])
        
        transcript = ' '.join(transcript_parts).strip()
        
        # Clean up converted file if it was created
        if wav_path != audio_path and os.path.exists(wav_path):
            os.unlink(wav_path)
        
        wf.close()
        
        if not transcript:
            raise Exception("No speech detected in audio file")
        
        logger.info(f"Voice to text conversion successful: {transcript}")
        return transcript
        
    except Exception as e:
        logger.error(f"Voice to text conversion failed: {str(e)}")
        raise Exception(f"Failed to convert voice to text: {str(e)}")

def call_openrouter_api(text: str) -> Dict[str, Any]:
    """Call OpenRouter API for intent recognition and entity extraction"""
    
    # Detailed prompt for consistent JSON output
    system_prompt = """You are a task management assistant. Analyze user input and determine their intent regarding task management.

ALWAYS respond with valid JSON in exactly this format:
{
  "intent": "<intent_name>",
  "task_name": "<string or null>",
  "task_time": "<ISO datetime string or null>",
  "raw_text": "<original user text>"
}

Intent types:
- "add_task": User wants to create a new task
- "update_task": User wants to modify an existing task
- "delete_task": User wants to remove a task
- "list_tasks": User wants to see their tasks
- "prioritize_tasks": User wants to organize/prioritize tasks
- "unrelated": User is asking about something not task-related

For task_time, extract any time/date mentions and convert to ISO format (YYYY-MM-DDTHH:MM:SS). If no specific time is mentioned, use null.

Examples:
- "Add buy groceries tomorrow at 3pm" ‚Üí {"intent": "add_task", "task_name": "buy groceries", "task_time": "2024-01-15T15:00:00", "raw_text": "Add buy groceries tomorrow at 3pm"}
- "Delete the meeting task" ‚Üí {"intent": "delete_task", "task_name": "meeting task", "task_time": null, "raw_text": "Delete the meeting task"}
- "What's the weather?" ‚Üí {"intent": "unrelated", "task_name": null, "task_time": null, "raw_text": "What's the weather?"}"""

    payload = {
        "model": MODEL_NAME,
        "messages": [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": text}
        ],
        "temperature": 0.1,
        "max_tokens": 300
    }
    
    headers = {
        "Authorization": f"Bearer {API_KEY}",
        "Content-Type": "application/json"
    }
    
    try:
        logger.info(f"Calling OpenRouter API for text: {text}")
        response = requests.post(OPENROUTER_URL, json=payload, headers=headers, timeout=30)
        response.raise_for_status()
        
        result = response.json()
        
        if 'choices' not in result or not result['choices']:
            raise Exception("Invalid API response format")
        
        ai_response = result['choices'][0]['message']['content'].strip()
        logger.info(f"OpenRouter API response: {ai_response}")
        
        # Parse JSON response
        try:
            parsed_result = json.loads(ai_response)
            
            # Ensure all required fields exist
            required_fields = ['intent', 'task_name', 'task_time', 'raw_text']
            for field in required_fields:
                if field not in parsed_result:
                    parsed_result[field] = None
            
            # Set raw_text to original input
            parsed_result['raw_text'] = text
            
            return parsed_result
            
        except json.JSONDecodeError as e:
            logger.error(f"Failed to parse AI response as JSON: {ai_response}")
            # Fallback response
            return {
                "intent": "unrelated",
                "task_name": None,
                "task_time": None,
                "raw_text": text
            }
        
    except requests.exceptions.RequestException as e:
        logger.error(f"OpenRouter API request failed: {str(e)}")
        raise Exception(f"API request failed: {str(e)}")
    except Exception as e:
        logger.error(f"OpenRouter API call failed: {str(e)}")
        raise Exception(f"AI processing failed: {str(e)}")

def process_text_input(text: str) -> Dict[str, Any]:
    """Process text input for intent recognition"""
    if not text or not text.strip():
        raise Exception("Text input is empty")
    
    try:
        result = call_openrouter_api(text.strip())
        
        # Handle unrelated intents with friendly message
        if result.get('intent') == 'unrelated':
            result['message'] = "I can only help with tasks right now."
        
        return result
        
    except Exception as e:
        logger.error(f"Text processing failed: {str(e)}")
        raise Exception(f"Failed to process text input: {str(e)}")

# =============================================================================
# app.py - Streamlit UI for Testing
# =============================================================================

import streamlit as st
import requests
import json
import tempfile
import os
from datetime import datetime

# Streamlit UI Configuration
st.set_page_config(
    page_title="To-Do NLP Automation Tester",
    page_icon="‚úÖ",
    layout="wide"
)

# API Configuration
FASTAPI_BASE_URL = "http://localhost:8000"

st.title("ü§ñ To-Do NLP Automation Tester")
st.markdown("Test the FastAPI service for task automation using text or voice input.")

# Sidebar with API status
st.sidebar.header("API Status")
try:
    health_response = requests.get(f"{FASTAPI_BASE_URL}/health", timeout=5)
    if health_response.status_code == 200:
        st.sidebar.success("‚úÖ API is online")
        health_data = health_response.json()
        st.sidebar.json(health_data)
    else:
        st.sidebar.error("‚ùå API is offline")
except:
    st.sidebar.error("‚ùå Cannot connect to API")
    st.sidebar.info("Make sure the FastAPI server is running on localhost:8000")

# Main interface
st.header("üìù Text Input Testing")

# Text input examples
example_texts = [
    "Add buy groceries tomorrow at 3pm",
    "Delete the meeting task",
    "Show me all my tasks",
    "Update the project deadline to Friday",
    "Prioritize my tasks for today",
    "What's the weather like?"
]

st.subheader("Example Inputs")
for i, example in enumerate(example_texts):
    col1, col2 = st.columns([4, 1])
    with col1:
        st.text(example)
    with col2:
        if st.button(f"Use", key=f"example_{i}"):
            st.session_state.text_input = example

# Text input box
text_input = st.text_area(
    "Enter your task-related text:",
    height=100,
    key="text_input",
    placeholder="e.g., 'Add buy groceries tomorrow at 3pm' or 'Delete the meeting task'"
)

if st.button("Process Text", type="primary"):
    if text_input.strip():
        with st.spinner("Processing text..."):
            try:
                response = requests.post(
                    f"{FASTAPI_BASE_URL}/process-text",
                    json={"text": text_input},
                    timeout=30
                )
                
                if response.status_code == 200:
                    result = response.json()
                    st.success("‚úÖ Text processed successfully!")
                    
                    # Display results in a nice format
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        st.subheader("Intent Recognition")
                        intent_color = "green" if result["intent"] != "unrelated" else "orange"
                        st.markdown(f"**Intent:** :{intent_color}[{result['intent']}]")
                        
                        if result.get("message"):
                            st.info(result["message"])
                    
                    with col2:
                        st.subheader("Extracted Information")
                        st.write(f"**Task Name:** {result.get('task_name', 'None')}")
                        st.write(f"**Task Time:** {result.get('task_time', 'None')}")
                    
                    st.subheader("Full JSON Response")
                    st.json(result)
                    
                else:
                    st.error(f"‚ùå Error: {response.status_code}")
                    st.text(response.text)
                    
            except Exception as e:
                st.error(f"‚ùå Connection error: {str(e)}")
    else:
        st.warning("Please enter some text first.")

# Footer
st.markdown("---")
st.markdown("### üîß Development Notes")
st.markdown("""
**Setup Steps:**
1. Install requirements: `pip install -r requirements.txt`
2. Set your OpenRouter API key in `nlp_utils.py`
3. Run FastAPI: `uvicorn main:app --reload`
4. Run Streamlit: `streamlit run app.py`
""")

# =============================================================================
# requirements.txt
# =============================================================================

"""
fastapi==0.104.1
uvicorn[standard]==0.24.0
python-multipart==0.0.6
requests==2.31.0
streamlit==1.28.2
pydantic==2.5.0
python-dateutil==2.8.2
"""

# =============================================================================
# Example cURL Commands
# =============================================================================

"""
# Test text processing
curl -X POST "http://localhost:8000/process-text" \
  -H "Content-Type: application/json" \
  -d '{"text": "Add buy groceries tomorrow at 3pm"}'

# Health check
curl -X GET "http://localhost:8000/health"

# Root endpoint
curl -X GET "http://localhost:8000/"
"""

# =============================================================================
# Setup Instructions
# =============================================================================

"""
SETUP INSTRUCTIONS:

1. Create project directory:
   mkdir todo-nlp-service
   cd todo-nlp-service

2. Install Python dependencies:
   pip install -r requirements.txt

3. Configure API key:
   - Get API key from https://openrouter.ai/
   - Update API_KEY variable in nlp_utils.py

4. Run the services:
   # Terminal 1 - FastAPI
   uvicorn main:app --reload --host 0.0.0.0 --port 8000
   
   # Terminal 2 - Streamlit UI
   streamlit run app.py

5. Test the endpoints:
   - FastAPI docs: http://localhost:8000/docs
   - Streamlit UI: http://localhost:8501
"""

# =============================================================================
# Mock Example Responses
# =============================================================================

"""
MOCK EXAMPLE RESPONSES:

1. Add Task:
Input: "Add buy groceries tomorrow at 3pm"
Response: {
  "intent": "add_task",
  "task_name": "buy groceries",
  "task_time": "2024-01-15T15:00:00",
  "raw_text": "Add buy groceries tomorrow at 3pm"
}

2. Delete Task:
Input: "Delete the meeting task"
Response: {
  "intent": "delete_task",
  "task_name": "meeting task",
  "task_time": null,
  "raw_text": "Delete the meeting task"
}

3. List Tasks:
Input: "Show me all my tasks"
Response: {
  "intent": "list_tasks",
  "task_name": null,
  "task_time": null,
  "raw_text": "Show me all my tasks"
}

4. Unrelated Query:
Input: "What's the weather?"
Response: {
  "intent": "unrelated",
  "task_name": null,
  "task_time": null,
  "raw_text": "What's the weather?",
  "message": "I can only help with tasks right now."
}

5. Update Task:
Input: "Update project deadline to Friday"
Response: {
  "intent": "update_task",
  "task_name": "project deadline",
  "task_time": "2024-01-19T00:00:00",
  "raw_text": "Update project deadline to Friday"
}
"""